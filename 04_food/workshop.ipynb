{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://vk.com/u_samovaraa?w=wall-81871567_61842\n",
    "- https://vk.com/vkys_nos?w=wall-41960737_13333\n",
    "- https://vk.com/receptik_kulinar?w=wall-59496329_52708\n",
    "- https://vk.com/lisimnik_cake?w=wall-82240292_25648\n",
    "- https://vk.com/kingcook?w=wall-59442940_11047\n",
    "- https://vk.com/u_samovaraa?w=wall-81871567_61917\n",
    "- https://vk.com/quickrecipes?w=wall-61337543_5892\n",
    "- https://vk.com/namenuru?w=wall-36303114_56579\n",
    "- https://vk.com/vegan_cookbook?w=wall-43818640_25903\n",
    "- https://vk.com/multivarka_cook?w=wall-51300483_11948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import iglob as list_paths\n",
    "\n",
    "\n",
    "def load_text(path):\n",
    "    with open(path) as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "texts = [\n",
    "    load_text(_)\n",
    "    for _ in list_paths('texts/*.txt')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_translation(source, target):\n",
    "    assert len(source) == len(target)\n",
    "    return {\n",
    "        ord(a): ord(b)\n",
    "        for a, b in zip(source, target)\n",
    "    }\n",
    "\n",
    "\n",
    "DASHES_TRANSLATION = make_translation(\n",
    "    '‑–—−',\n",
    "    '----'\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = text.replace('\\xad', '')\n",
    "    text = text.translate(DASHES_TRANSLATION)\n",
    "    return text\n",
    "\n",
    "\n",
    "texts = [preprocess(_) for _ in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def find_ingredient_sections(text):\n",
    "    return re.findall(r'ингредиенты:(.+?)приготовление', text, re.I | re.S)\n",
    "\n",
    "\n",
    "\n",
    "def maybe_ingredient(line):\n",
    "    match = re.search(r'\\d', line)\n",
    "    size = len(line) <= 50\n",
    "    return match and size\n",
    "\n",
    "\n",
    "lines = []\n",
    "for text in texts:\n",
    "    sections = find_ingredient_sections(text)\n",
    "    for section in sections:\n",
    "        for line in section.splitlines():\n",
    "            if maybe_ingredient(line):\n",
    "                lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, sample\n",
    "\n",
    "seed(1)\n",
    "sample(lines, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yargy.tokenizer import MorphTokenizer\n",
    "\n",
    "\n",
    "TOKENIZER = MorphTokenizer()\n",
    "\n",
    "\n",
    "list(TOKENIZER('Соль - 2 ст.ложки'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipymarkup import show_markup\n",
    "\n",
    "from yargy import rule, Parser\n",
    "from yargy.predicates import eq\n",
    "\n",
    "\n",
    "MEASURE = rule(eq('100'), eq('г'))\n",
    "parser = Parser(MEASURE)\n",
    "seed(1)\n",
    "for line in sample(lines, 100):\n",
    "    matches = list(parser.findall(line))\n",
    "    spans = [_.span for _ in matches]\n",
    "    show_markup(line, spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yargy import or_\n",
    "from yargy.predicates import type, normalized\n",
    "from yargy.pipelines import morph_pipeline\n",
    "\n",
    "INT = type('INT')\n",
    "\n",
    "NAME = morph_pipeline([\n",
    "    'мл',\n",
    "    'литр',\n",
    "\n",
    "    'г',\n",
    "    'гр',\n",
    "    'грамм',\n",
    "\n",
    "    'шт',\n",
    "    'штука',\n",
    "    'пачка',\n",
    "\n",
    "    'ст',\n",
    "    'чаш',\n",
    "    'стакан',\n",
    "    'горсть',\n",
    "\n",
    "    'зубчик',\n",
    "    'зуб',\n",
    "    \n",
    "    'ст.л',\n",
    "    'ст.ложка',\n",
    "    'столовая ложка',\n",
    "\n",
    "    'ч.л',\n",
    "    'ч.ложка',\n",
    "    'чайная ложка',\n",
    "])\n",
    "\n",
    "UNIT = rule(\n",
    "    NAME,\n",
    "    eq('.').optional()\n",
    ")\n",
    "\n",
    "MEASURE = rule(INT, UNIT)\n",
    "\n",
    "parser = Parser(MEASURE)\n",
    "seed(1)\n",
    "for line in sample(lines, 100):\n",
    "    matches = list(parser.findall(line))\n",
    "    spans = [_.span for _ in matches]\n",
    "    show_markup(line, spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yargy.predicates import in_\n",
    "\n",
    "\n",
    "FLOAT = rule(\n",
    "    INT,\n",
    "    in_('.,'),\n",
    "    INT\n",
    ")\n",
    "\n",
    "FRACTION = rule(\n",
    "    INT,\n",
    "    '/',\n",
    "    INT\n",
    ")\n",
    "\n",
    "RANGE = rule(\n",
    "    INT,\n",
    "    '-',\n",
    "    INT\n",
    ")\n",
    "\n",
    "AMOUNT = or_(\n",
    "    rule(INT),\n",
    "    FLOAT,\n",
    "    FRACTION,\n",
    "    RANGE\n",
    ")\n",
    "\n",
    "MEASURE = rule(AMOUNT, UNIT)\n",
    "\n",
    "parser = Parser(MEASURE)\n",
    "seed(1)\n",
    "for line in sample(lines, 100):\n",
    "    matches = list(parser.findall(line))\n",
    "    spans = [_.span for _ in matches]\n",
    "    show_markup(line, spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = or_(\n",
    "    rule('a', 'b'),\n",
    "    rule('c').optional().repeatable()\n",
    ")\n",
    "\n",
    "R.normalized.as_bnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yargy.predicates import gram\n",
    "\n",
    "\n",
    "NOUN = gram('NOUN')\n",
    "ADJF = or_(\n",
    "    gram('ADJF'),\n",
    "    gram('PRTF')\n",
    ")\n",
    "\n",
    "MODIFIER = ADJF.repeatable()\n",
    "\n",
    "PRODUCT = rule(\n",
    "    MODIFIER.optional(),\n",
    "    NOUN,\n",
    "    MODIFIER.optional()\n",
    ")\n",
    "\n",
    "parser = Parser(or_(PRODUCT, MEASURE))\n",
    "seed(1)\n",
    "for line in sample(lines, 100):\n",
    "    matches = list(parser.findall(line))\n",
    "    spans = [_.span for _ in matches]\n",
    "    show_markup(line, spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP = in_('-:')\n",
    "\n",
    "MEASURE = rule(\n",
    "    AMOUNT,\n",
    "    UNIT.optional()\n",
    ")\n",
    "\n",
    "INGREDIENT = or_(\n",
    "    rule(\n",
    "        MEASURE,\n",
    "        SEP.optional(),\n",
    "        PRODUCT\n",
    "    ),\n",
    "    rule(\n",
    "        PRODUCT,\n",
    "        SEP.optional(),\n",
    "        MEASURE\n",
    "    )\n",
    ")\n",
    "\n",
    "parser = Parser(INGREDIENT)\n",
    "seed(1)\n",
    "for line in sample(lines, 100):\n",
    "    matches = list(parser.findall(line))\n",
    "    spans = [_.span for _ in matches]\n",
    "    show_markup(line, spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yargy.interpretation import fact\n",
    "\n",
    "\n",
    "Measure = fact(\n",
    "    'Measure',\n",
    "    ['amount', 'unit']\n",
    ")\n",
    "\n",
    "AMOUNT = eq('100').interpretation(\n",
    "    Measure.amount.custom(int)\n",
    ")\n",
    "\n",
    "UNIT = normalized('грамм').interpretation(\n",
    "    Measure.unit.normalized()\n",
    ")\n",
    "\n",
    "MEASURE = rule(AMOUNT, UNIT).interpretation(\n",
    "    Measure\n",
    ")\n",
    "\n",
    "parser = Parser(MEASURE)\n",
    "match = parser.match('100 граммов')\n",
    "match.tree.as_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match.fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "Measure = fact(\n",
    "    'Measure',\n",
    "    ['amount', 'unit']\n",
    ")\n",
    "Product = fact(\n",
    "    'Product',\n",
    "    ['name', 'modifiers']\n",
    ")\n",
    "Ingredient = fact(\n",
    "    'Ingredient',\n",
    "    ['measure', 'product']\n",
    ")\n",
    "\n",
    "\n",
    "DIGIT = INT.interpretation(\n",
    "    Measure.amount.custom(int)\n",
    ")\n",
    "\n",
    "FLOAT = rule(\n",
    "    INT,\n",
    "    in_('.,'),\n",
    "    INT\n",
    ").interpretation(\n",
    "    Measure.amount.custom(lambda _: _.replace(',', '.'))\n",
    ")\n",
    "\n",
    "def parse_fraction(value):\n",
    "    n, d = value.split('/')\n",
    "    return Fraction(int(n), int(d))\n",
    "\n",
    "FRACTION = rule(\n",
    "    INT,\n",
    "    '/',\n",
    "    INT\n",
    ").interpretation(\n",
    "    Measure.amount.custom(parse_fraction)\n",
    ")\n",
    "\n",
    "def parse_range(value):\n",
    "    a, b = value.split('-')\n",
    "    return int(a), int(b)\n",
    "\n",
    "RANGE = rule(\n",
    "    INT,\n",
    "    '-',\n",
    "    INT\n",
    ").interpretation(\n",
    "    Measure.amount.custom(parse_range)\n",
    ")\n",
    "\n",
    "AMOUNT = or_(\n",
    "    DIGIT,\n",
    "    FLOAT,\n",
    "    FRACTION,\n",
    "    RANGE\n",
    ")\n",
    "\n",
    "NAME = morph_pipeline([\n",
    "    'мл',\n",
    "    'литр',\n",
    "\n",
    "    'г',\n",
    "    'гр',\n",
    "    'грамм',\n",
    "\n",
    "    'шт',\n",
    "    'штука',\n",
    "    'пачка',\n",
    "\n",
    "    'ст',\n",
    "    'чаш',\n",
    "    'стакан',\n",
    "    'горсть',\n",
    "\n",
    "    'зубчик',\n",
    "    'зуб',\n",
    "    \n",
    "    'ст.л',\n",
    "    'ст.ложка',\n",
    "    'столовая ложка',\n",
    "\n",
    "    'ч.л',\n",
    "    'ч.ложка',\n",
    "    'чайная ложка',\n",
    "]).interpretation(\n",
    "    Measure.unit.normalized()\n",
    ")\n",
    "\n",
    "UNIT = rule(\n",
    "    NAME,\n",
    "    eq('.').optional()\n",
    ")\n",
    "\n",
    "MEASURE = rule(\n",
    "    AMOUNT,\n",
    "    UNIT.optional()\n",
    ").interpretation(\n",
    "    Measure\n",
    ")\n",
    "\n",
    "NOUN = gram('NOUN')\n",
    "ADJF = or_(\n",
    "    gram('ADJF'),\n",
    "    gram('PRTF')\n",
    ")\n",
    "\n",
    "MODIFIER = ADJF.repeatable().interpretation(\n",
    "    Product.modifiers.normalized()\n",
    ")\n",
    "\n",
    "PRODUCT = rule(\n",
    "    MODIFIER.optional(),\n",
    "    NOUN.interpretation(Product.name.normalized()),\n",
    "    MODIFIER.optional()\n",
    ").interpretation(\n",
    "    Product\n",
    ")\n",
    "\n",
    "SEP = in_('-:')\n",
    "\n",
    "INGREDIENT = or_(\n",
    "    rule(\n",
    "        MEASURE.interpretation(Ingredient.measure),\n",
    "        SEP.optional(),\n",
    "        PRODUCT.interpretation(Ingredient.product)\n",
    "    ),\n",
    "    rule(\n",
    "        PRODUCT.interpretation(Ingredient.product),\n",
    "        SEP.optional(),\n",
    "        MEASURE.interpretation(Ingredient.measure)\n",
    "    )\n",
    ").interpretation(\n",
    "    Ingredient\n",
    ")\n",
    "\n",
    "parser = Parser(INGREDIENT)\n",
    "seed(1)\n",
    "for line in sample(lines, 100):\n",
    "    matches = list(parser.findall(line))\n",
    "    spans = [_.span for _ in matches]\n",
    "    show_markup(line, spans)\n",
    "    if matches:\n",
    "        match = matches[0]\n",
    "        display(match.tree.as_dot)\n",
    "        display(match.fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
